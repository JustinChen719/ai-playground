{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 数据预处理",
   "id": "adce63022dc5ee72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:23:30.137430Z",
     "start_time": "2025-01-17T13:23:26.817157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ],
   "id": "50609ea2e44bb63f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since wikitext couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'wikitext-2-raw-v1' at C:\\Users\\chenzhen\\.cache\\huggingface\\datasets\\wikitext\\wikitext-2-raw-v1\\0.0.0\\b08601e04326c79dfdd32d625aee71d232d685c3 (last modified on Tue Dec 31 19:06:50 2024).\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "对数据进行分词、编码",
   "id": "c0e4aec12e0b1414"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:23:34.228571Z",
     "start_time": "2025-01-17T13:23:30.145041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert/distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ],
   "id": "13a9baa29671fed8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T13:23:34.359002Z",
     "start_time": "2025-01-17T13:23:34.296461Z"
    }
   },
   "source": "tokenized_dataset = datasets.map(tokenize_function, batched=True, num_proc=1, remove_columns=\"text\")",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "对数据进行合并再切分，这样可以不是用padding来填充，有效利用空闲空间。",
   "id": "370cb001ac04f196"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:23:34.370192Z",
     "start_time": "2025-01-17T13:23:34.367320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(examples):\n",
    "    # 拼接所有文本\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # 我们将余数对应的部分去掉。但如果模型支持的话，可以添加padding，您可以根据需要定制此部件。\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # 通过max_len进行分割。\n",
    "    result = {\n",
    "        k: [t[i: i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "id": "66d071b2eb3def33",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:23:34.405390Z",
     "start_time": "2025-01-17T13:23:34.379225Z"
    }
   },
   "cell_type": "code",
   "source": "lm_dataset = tokenized_dataset.map(group_texts, batched=True, batch_size=1000)",
   "id": "fae57e46261d0fe0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 加载模型",
   "id": "cdaceede255e29b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:23:35.824895Z",
     "start_time": "2025-01-17T13:23:34.412902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ],
   "id": "c6d402f6f0ec4c6e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 训练",
   "id": "3ce0ebc0dceef128"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:24:17.965091Z",
     "start_time": "2025-01-17T13:23:35.834227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir= \"output\",\n",
    "    eval_strategy= \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    eval_delay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"validation\"]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "68fb7e33aa78c685",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenzhen\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:545: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='351' max='7002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 351/7002 00:38 < 12:19, 9.00 it/s, Epoch 0.15/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 17\u001B[0m\n\u001B[0;32m      3\u001B[0m args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[0;32m      4\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      5\u001B[0m     eval_strategy\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m     learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2e-5\u001B[39m,\n\u001B[0;32m      7\u001B[0m     eval_delay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m\n\u001B[0;32m      8\u001B[0m )\n\u001B[0;32m     10\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     11\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     12\u001B[0m     args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m     13\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mlm_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     14\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39mlm_dataset[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     15\u001B[0m )\n\u001B[1;32m---> 17\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\trainer.py:2164\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   2162\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   2163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inner_training_loop(\n\u001B[0;32m   2165\u001B[0m         args\u001B[38;5;241m=\u001B[39margs,\n\u001B[0;32m   2166\u001B[0m         resume_from_checkpoint\u001B[38;5;241m=\u001B[39mresume_from_checkpoint,\n\u001B[0;32m   2167\u001B[0m         trial\u001B[38;5;241m=\u001B[39mtrial,\n\u001B[0;32m   2168\u001B[0m         ignore_keys_for_eval\u001B[38;5;241m=\u001B[39mignore_keys_for_eval,\n\u001B[0;32m   2169\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\trainer.py:2473\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2471\u001B[0m update_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2472\u001B[0m num_batches \u001B[38;5;241m=\u001B[39m args\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps \u001B[38;5;28;01mif\u001B[39;00m update_step \u001B[38;5;241m!=\u001B[39m (total_updates \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m remainder\n\u001B[1;32m-> 2473\u001B[0m batch_samples, num_items_in_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_batch_samples(epoch_iterator, num_batches)\n\u001B[0;32m   2474\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, inputs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(batch_samples):\n\u001B[0;32m   2475\u001B[0m     step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\trainer.py:5130\u001B[0m, in \u001B[0;36mTrainer.get_batch_samples\u001B[1;34m(self, epoch_iterator, num_batches)\u001B[0m\n\u001B[0;32m   5128\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_batches):\n\u001B[0;32m   5129\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 5130\u001B[0m         batch_samples \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mnext\u001B[39m(epoch_iterator)]\n\u001B[0;32m   5131\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m   5132\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\accelerate\\data_loader.py:561\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    559\u001B[0m     \u001B[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001B[39;00m\n\u001B[0;32m    560\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 561\u001B[0m         current_batch \u001B[38;5;241m=\u001B[39m send_to_device(current_batch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, non_blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_non_blocking)\n\u001B[0;32m    562\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_state_dict()\n\u001B[0;32m    563\u001B[0m     next_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(dataloader_iter)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\accelerate\\utils\\operations.py:185\u001B[0m, in \u001B[0;36msend_to_device\u001B[1;34m(tensor, device, non_blocking, skip_keys)\u001B[0m\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m skip_keys \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    182\u001B[0m         skip_keys \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(tensor)(\n\u001B[0;32m    184\u001B[0m         {\n\u001B[1;32m--> 185\u001B[0m             k: t \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m skip_keys \u001B[38;5;28;01melse\u001B[39;00m send_to_device(t, device, non_blocking\u001B[38;5;241m=\u001B[39mnon_blocking, skip_keys\u001B[38;5;241m=\u001B[39mskip_keys)\n\u001B[0;32m    186\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m k, t \u001B[38;5;129;01min\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m    187\u001B[0m         }\n\u001B[0;32m    188\u001B[0m     )\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\accelerate\\utils\\operations.py:156\u001B[0m, in \u001B[0;36msend_to_device\u001B[1;34m(tensor, device, non_blocking, skip_keys)\u001B[0m\n\u001B[0;32m    154\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxpu:0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mto(device, non_blocking\u001B[38;5;241m=\u001B[39mnon_blocking)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:  \u001B[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001B[39;00m\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tensor\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4 检验效果",
   "id": "fbaea9c5599b23f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:24:24.549679Z",
     "start_time": "2025-01-17T13:24:24.370922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 微调以后的效果\n",
    "model = AutoModelForCausalLM.from_pretrained(\"models/causallm-distilgpt2\")\n",
    "text = \"Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input).logits\n",
    "tokenizer.decode(output[0].argmax(-1))"
   ],
   "id": "4024d15049f69a13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' , the 2010 , the , and was the first game in the seriesalkyria Chronicles to Iting a same name system the elements tactical @-@ time combat , the predecessor , the game is'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:24:26.050999Z",
     "start_time": "2025-01-17T13:24:25.700170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 原本模型输出效果\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n",
    "text = \"Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input).logits\n",
    "tokenizer.decode(output[0].argmax(-1))"
   ],
   "id": "fd0c29c4f95e52b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The the,. the. the was the first time in the series-ria Chronicles to Iting a same name system the and tactical-klife style,, the predecessor, the game is'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
