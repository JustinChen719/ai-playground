{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1 数据预处理\n",
    "\n"
   ],
   "id": "1094774b931564d4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T07:05:16.207821Z",
     "start_time": "2024-12-17T07:05:10.780711Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "data_path = 'data/toutiao_data.txt'\n",
    "with open(data_path, 'r', encoding='utf-8') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# 预处理\n",
    "data = np.array([line[:-1].strip().split('_!_') for line in data])\n",
    "data = pd.DataFrame(data, columns=['news_id', 'label', 'label_name', 'text', 'key_words'])\n",
    "data.drop(['news_id', 'label_name'], axis=1, inplace=True)\n",
    "data['label'] = data['label'].astype(int)\n",
    "data['text'] = data['text'].astype(str)\n",
    "data['key_words'] = data['key_words'].astype(str)\n",
    "print(data.info())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 382688 entries, 0 to 382687\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   label      382688 non-null  int32 \n",
      " 1   text       382688 non-null  object\n",
      " 2   key_words  382688 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 7.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:05:17.536694Z",
     "start_time": "2024-12-17T07:05:17.374379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scale = 0.1\n",
    "train_ratio = 0.8\n",
    "total_size = int(data.shape[0] * scale)\n",
    "train_size = int(total_size * train_ratio)\n",
    "\n",
    "data = data.sample(frac=scale, random_state=42)\n",
    "\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "train_text = train_data.apply(lambda x: x['text'] + \",\" +  x['key_words'], axis=1).tolist()\n",
    "train_label = train_data['label'].values\n",
    "test_text = test_data.apply(lambda x: x['text'] + \",\" +  x['key_words'], axis=1).tolist()\n",
    "test_label = test_data['label'].values"
   ],
   "id": "89d94c4077a295dc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:05:26.413806Z",
     "start_time": "2024-12-17T07:05:20.057037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "train_text = tokenizer(train_text, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "test_text = tokenizer(test_text, padding=True, truncation=True, max_length=128, return_tensors='pt')"
   ],
   "id": "9f1146ef514dd3b8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:05:34.968896Z",
     "start_time": "2024-12-17T07:05:34.965824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(train_text)\n",
    "# print(train_label)\n",
    "# print(test_text)\n",
    "# print(test_label)\n",
    "\n",
    "label2name = {\n",
    "    100: '民生',\n",
    "    101: '文化',\n",
    "    102: '娱乐',\n",
    "    103: '体育',\n",
    "    104: '财经',\n",
    "    106: '房产',\n",
    "    107: '汽车',\n",
    "    108: '教育',\n",
    "    109: '科技',\n",
    "    110: '军事',\n",
    "    112: '旅游',\n",
    "    113: '国际',\n",
    "    114: '证券',\n",
    "    115: '农业',\n",
    "    116: '电竞'\n",
    "}\n",
    "label_size = len(label2name) + 2"
   ],
   "id": "d3e76ea3dbfb58cc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 模型训练",
   "id": "b2c1ad7ff710c0a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:05:39.581480Z",
     "start_time": "2024-12-17T07:05:39.555454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs, batch_size = 5, 512\n",
    "lr = 5e-3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "id": "bbd9af3f26f3a3da",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T07:06:03.721701Z",
     "start_time": "2024-12-17T07:05:41.863796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TensorDataset(train_text['input_ids'], train_text['attention_mask'], torch.tensor(train_label))\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(test_text['input_ids'], test_text['attention_mask'], torch.tensor(test_label))\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=label_size, local_files_only=True)\n",
    "# 除了最后一层\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs * len(train_data_loader))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    bar = tqdm(train_data_loader)\n",
    "    bar.set_description(f'Epoch {epoch+1}/{epochs}')\n",
    "    for i, batch in enumerate(bar):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        label = label.long() - 100\n",
    "        input_ids, attention_mask, label = input_ids.to(device), attention_mask.to(device), label.to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        loss = criterion(logits, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bar.set_postfix(loss=loss.item())\n",
    "        scheduler.step()\n",
    "\n"
   ],
   "id": "653aca98c40ed26f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/5:   0%|          | 0/60 [00:00<?, ?it/s]C:\\Users\\chenzhen\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Epoch 1/5:  22%|██▏       | 13/60 [00:21<01:16,  1.63s/it, loss=2.03]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 31\u001B[0m\n\u001B[0;32m     28\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     29\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 31\u001B[0m bar\u001B[38;5;241m.\u001B[39mset_postfix(loss\u001B[38;5;241m=\u001B[39mloss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m     32\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 模型评估",
   "id": "eb88f6baaecbf832"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T02:42:41.347082Z",
     "start_time": "2024-12-17T02:42:36.008528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "for batch in tqdm(test_data_loader):\n",
    "    input_ids, attention_mask, label = batch\n",
    "    label = label.long() - 100\n",
    "\n",
    "    input_ids, attention_mask, label = input_ids.to(device), attention_mask.to(device), label.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        correct += torch.sum(pred == label).item()\n",
    "        total += label.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct / total:.4f}')"
   ],
   "id": "8a6f474db8dd7112",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T02:46:57.741890Z",
     "start_time": "2024-12-17T02:46:57.600347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 随机选一些展示效果\n",
    "random_samples = []\n",
    "for i in range(10):\n",
    "    random_samples.append(test_data.sample(1))\n",
    "\n",
    "for sample in random_samples:\n",
    "    text = sample['text'].values[0] + \",\" + sample['key_words'].values[0]\n",
    "    true_label = sample['label'].values[0]\n",
    "\n",
    "    token = tokenizer(text, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    pred = model(token['input_ids'].to(device), attention_mask=token['attention_mask'].to(device)).logits\n",
    "    pred = torch.argmax(pred, dim=1).item()  + 100\n",
    "\n",
    "    print(f'{text} \\n True Label: {label2name[true_label]} \\n Pred Label: {label2name[pred]}\\n')"
   ],
   "id": "f41e88a58b302c01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "口碑最好的10万级合资车，油耗4毛，关键是一年买几十万台,桑塔纳,PASS,威驰,轩逸,爱丽舍 \n",
      " True Label: 汽车 \n",
      " Pred Label: 汽车\n",
      "\n",
      "阚清子拖着“沉重”的身躯默默行走在机场，面无表情尽显疲惫,纪凌尘,阚清子,综艺节目,机场 \n",
      " True Label: 娱乐 \n",
      " Pred Label: 娱乐\n",
      "\n",
      "又一女团成员确定结婚！本月20日举行婚礼,婚礼,女团,Nine Muses,结为连理,DJ Da.Q \n",
      " True Label: 娱乐 \n",
      " Pred Label: 娱乐\n",
      "\n",
      "娱乐圈真正的“冻龄女神”，71年龄却保持着18岁的脸,娃娃脸,一代女皇,还珠格格,冻龄,潘迎紫,宋慧乔,武媚娘传奇 \n",
      " True Label: 娱乐 \n",
      " Pred Label: 娱乐\n",
      "\n",
      "日本新兵因受不了虐待，满载炸弹撞向指挥部，当场炸死30名长官,攻击队,日本,新兵,武士道精神 \n",
      " True Label: 军事 \n",
      " Pred Label: 军事\n",
      "\n",
      "《三国机密之潜龙在渊》热播 马天宇身份泄漏韩东君遭受酷刑,司马懿,刘平,曹操,郭嘉,任红昌 \n",
      " True Label: 娱乐 \n",
      " Pred Label: 娱乐\n",
      "\n",
      "为什么坦克世界没人玩？,英雄联盟,排位赛,梦三国,百夫长,坦克世界,游戏 \n",
      " True Label: 电竞 \n",
      " Pred Label: 电竞\n",
      "\n",
      "5000公里必换机油？恭喜你中了4S店的套路，一招辨别该不该换机油,宝马,机油,换机油,4s店 \n",
      " True Label: 汽车 \n",
      " Pred Label: 汽车\n",
      "\n",
      "给孩子起名“女起诗经男起楚辞”的文化含意,邶风·新台,鄘风·君子偕老,邶风·静女,湘夫人,雨巷,周南·桃夭,郑风·出其东门,邶风·燕燕,灵均,诗经,离骚,邶风·,楚辞,周信芳,郑风·叔于田 \n",
      " True Label: 文化 \n",
      " Pred Label: 文化\n",
      "\n",
      "为什么那么多人去上海的城隍庙？,玉华堂日记,龙宿郊民图,怀庆府推官刘君墓表,南吴旧话录,明朝,溪山秋霁图,刘钝,董其昌,潘允端,归有光 \n",
      " True Label: 文化 \n",
      " Pred Label: 文化\n",
      "\n"
     ]
    }
   ],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
